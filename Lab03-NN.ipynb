{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b703febb",
   "metadata": {},
   "source": [
    "# Lab-03 Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d37c9ad",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd247956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images:  2177\n",
      "Total images path:  2177\n",
      "Total Postures:  9\n",
      "Total images_pixels:  2177\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "\n",
    "images = []\n",
    "pose_name = []\n",
    "images_path = []\n",
    "images_pixels = []\n",
    "labels = []\n",
    "\n",
    "dict = {}\n",
    "\n",
    "i=0\n",
    "dataPath = './yogaData'\n",
    "\n",
    "for directory in os.listdir(dataPath):\n",
    "    dirPath = os.path.join(dataPath, directory)\n",
    "    if os.path.isdir(dirPath):\n",
    "        pose_name.append(directory)\n",
    "        for img in os.listdir(dirPath):\n",
    "            if len(re.findall('.png',img.lower())) != 0 or len(re.findall('.jpg',img.lower())) != 0 or len(re.findall('.jpeg',img.lower())) != 0:\n",
    "                img_path = os.path.join(dirPath,img)\n",
    "                images.append(img)\n",
    "                images_path.append(img_path)\n",
    "                img_pix = cv2.imread(img_path,1)\n",
    "                images_pixels.append(cv2.resize(img_pix, (100,100)))\n",
    "                labels.append(i)\n",
    "        \n",
    "    i = i+1\n",
    "            \n",
    "print(\"Total images: \", len(images))\n",
    "print(\"Total images path: \", len(images_path))\n",
    "print(\"Total postures: \", len(pose_name))\n",
    "print(\"Total images_pixels: \", len(images_pixels))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dc133df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "shuffled = list(zip(images_pixels,labels))\n",
    "random.shuffle(shuffled)\n",
    "\n",
    "train_data, labels_data = zip(*shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a33ce89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "X_data = np.array(train_data)/255\n",
    "Y_data =  to_categorical(labels_data, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fac3aa7",
   "metadata": {},
   "source": [
    "## Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af66b307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4380e53f",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da20ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f128483b",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ba27f0",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a8d4937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, Y, transform=None):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_sample = self.X[idx]\n",
    "        y_sample = self.Y[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            x_sample = self.transform(x_sample)\n",
    "            \n",
    "        return x_sample, y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "696b8df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts the image to a PyTorch tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2148485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bfcea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a2959fb",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
